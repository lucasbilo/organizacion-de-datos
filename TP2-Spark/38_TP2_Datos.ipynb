{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1sER1r3k5Ht"
      },
      "source": [
        "**38. Si decimos que la ubicación de un usuario es el promedio de la latitud y longitud de\n",
        "los contenidos geolocalizados para los cuales editó la última versión (ignorar\n",
        "usuarios que no editaron contenido geolocalizado). ¿Cuáles son los dos usuarios\n",
        "más cercanos?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4yc-KoJkbG4",
        "outputId": "3fee9564-320a-4f45-87f4-fabaea62608b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 23 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 50.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=65ba05ae07c9f06b9920c56e36fc625ba9e931265b35a652f6145f16c93ef9c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "0% [1 InRelease gpgv 1,581 B] [4 InRelease 15.6 kB/88.7 kB 18%] [Waiting for he\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt update\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "#!apt install default-jre\n",
        "#!apt install default-jdk\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "of6WS23SkgrF"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slGIwNSxkeuY"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz38rivmkhy2"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9w3LWa6lpcx"
      },
      "source": [
        "Para este ejercicio voy a utilizar el csv contents y geo_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9QIEzljki9d"
      },
      "outputs": [],
      "source": [
        "downloaded = drive.CreateFile({'id':'1SnCVFJvTsaEPrmh-PpVGH6-toBVsD6NL'})\n",
        "downloaded.GetContentFile('contents.csv')\n",
        "\n",
        "downloaded2 = drive.CreateFile({'id':'1qLu79VkVJxWp9i4Pnq9cxSLjW6Nipxp9'})\n",
        "downloaded2.GetContentFile('geo_tags.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLrvQHJtkjxs"
      },
      "outputs": [],
      "source": [
        "!pip install pyarrow\n",
        "texts = pd.read_csv('contents.csv')\n",
        "texts.to_parquet('contents.parquet')\n",
        "del texts\n",
        "\n",
        "sqlContext = SQLContext(sc)\n",
        "df = sqlContext.read.parquet('contents.parquet')\n",
        "rdd1 = df.rdd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkC3j7dGkmCw"
      },
      "outputs": [],
      "source": [
        "texts = pd.read_csv('geo_tags.csv')\n",
        "texts.to_parquet('geo_tags.parquet')\n",
        "del texts\n",
        "\n",
        "sqlContext = SQLContext(sc)\n",
        "df2 = sqlContext.read.parquet('geo_tags.parquet')\n",
        "rdd2 = df2.rdd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfqqgdJdmsvk"
      },
      "outputs": [],
      "source": [
        "contents = rdd1.map(lambda x: (x.id, x.revisor_username if x.revisor_username != None else x.revisor_ip))\n",
        "contents.take(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2gtyE3vmCAd"
      },
      "outputs": [],
      "source": [
        "geo = rdd2.map(lambda x: (x.gt_page_id, (x.gt_lat, x.gt_lon)))\n",
        "geo.take(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V738UGWvoJfB"
      },
      "outputs": [],
      "source": [
        "join = contents.join(geo)\n",
        "join.take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PpkUEUAodaK"
      },
      "outputs": [],
      "source": [
        "join.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1JWzmfA3qmh"
      },
      "source": [
        "Mapeo para que me quede de la forma: USUARIO - LATITUD(contenido) - LONGITUD(contenido)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lixut1Nc3XI6"
      },
      "outputs": [],
      "source": [
        "join.map(lambda x: (x[1][0], (1, x[1][1][0], x[1][1][1]))).take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOznsGAG5sR7"
      },
      "source": [
        "Reduzco por los usuarios, contando sus ocurrencias y sumando las latitudes y longitudes para posteriormente calcular los promedios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_8qL_T543mi"
      },
      "outputs": [],
      "source": [
        "join.map(lambda x: (x[1][0], (1, x[1][1][0], x[1][1][1]))).reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1], a[2]+b[2])).take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SWLp1Vb5y5Y"
      },
      "source": [
        "Finalmente tengo a los usuario con sus posiciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcrpUJCg5deq"
      },
      "outputs": [],
      "source": [
        "join.map(lambda x: (x[1][0], (1, x[1][1][0], x[1][1][1])))\\\n",
        "  .reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1], a[2]+b[2]))\\\n",
        "  .map(lambda x: (x[0], (x[1][1]/x[1][0],x[1][2]/x[1][0]))).take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVIPzMLE5246"
      },
      "outputs": [],
      "source": [
        "usuarios = join.map(lambda x: (x[1][0], (1, x[1][1][0], x[1][1][1])))\\\n",
        "                .reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1], a[2]+b[2]))\\\n",
        "                .map(lambda x: (x[0], (x[1][1]/x[1][0],x[1][2]/x[1][0]))).cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCdG75XSehZX"
      },
      "source": [
        "Voy a utilizar un BallTree para poder buscar el vecino más cercano de cada usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1weSRy46hsc"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import BallTree\n",
        "import numpy as np\n",
        "\n",
        "lats = usuarios.map(lambda x: x[1][0]).collect()\n",
        "lons = usuarios.map(lambda x: x[1][1]).collect()\n",
        "\n",
        "bt = BallTree(np.deg2rad(usuarios.map(lambda x: (x[1][0],x[1][1])).collect()), metric='haversine')\n",
        "distances, indices = bt.query(np.deg2rad(np.c_[lats, lons]), k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfO8hC0HekXx"
      },
      "source": [
        "El array distances tendrá las distancias de los 2 vecinos más cercanos, donde siempre el primer valor será 0 (distancia a el mismo) y el segundo tendrá un valor distinto de cero.\n",
        "\n",
        "El array indices tendrá también 2 valores, el primero será el mismo y el 2do será el indice del vecino más cercano (distinto de él)\n",
        "\n",
        "Aunque en este set de datos hay casos particulares, los cuales son usuarios en exactamente la misma ubicación (esto hace que a veces se calcule primero la distancia al otro y luego a si mismo (los datos estarían cruzados))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ervq6HlGeubh"
      },
      "source": [
        "Paso las distancias a KM multiplicando por 6371 que es el radio de la tierra en km."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IisKl4CFIl4"
      },
      "outputs": [],
      "source": [
        "radio = 6371\n",
        "for i in range(0, len(distances)):\n",
        "  distances[i][1] = distances[i][1] * radio\n",
        "\n",
        "print(distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrpFTYUIFNX_"
      },
      "outputs": [],
      "source": [
        "print(indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewa1qcgBey_b"
      },
      "source": [
        "Ahora voy a identificar cada usuario con su indice correspondiente.\n",
        "\n",
        "El usuario 0 es el primer usuario que aparece en el RDD **usuarios**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6stB1TblZI72"
      },
      "outputs": [],
      "source": [
        "lista_usuarios = usuarios.map(lambda x: x[0]).collect()\n",
        "aux = np.c_[indices, lista_usuarios].tolist()\n",
        "\n",
        "for elem in aux:\n",
        "  for i in range(1, len(aux)):\n",
        "    if elem[1] == aux[i][0]:\n",
        "        elem.append(aux[i][2])\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TC3EoB1frCq"
      },
      "source": [
        "Entonces, para el usuario 'Lojwe' el más cercano es el usuario 'Rodm23 mantenimiento' y viceversa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9zGoEpGfYKa"
      },
      "outputs": [],
      "source": [
        "aux[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6XKGC7jokd8"
      },
      "source": [
        "Están a una distancia de 85,76 km:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjnQrr3Pjemf"
      },
      "outputs": [],
      "source": [
        "distances[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4v5lDdgot6H"
      },
      "outputs": [],
      "source": [
        "distances[332]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDdc1kndovQ_"
      },
      "source": [
        "Junto todo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moX29eNmjxN1"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(aux)):\n",
        "  aux[i].append((distances[i][0], distances[i][1]))\n",
        "\n",
        "aux[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OSPJh6ipu9m"
      },
      "source": [
        "Convierto a RDD y mapeo con los datos que necesito:\n",
        "\n",
        "USUARIO - VECINO + CERCANO - DISTANCIA(KM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQG7jmOXpO6O"
      },
      "outputs": [],
      "source": [
        "rdd_vecinos = sc.parallelize(aux).map(lambda x: (x[2], (x[3], x[4][1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqhuxaFvprNG"
      },
      "outputs": [],
      "source": [
        "rdd_vecinos.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9kGxMF_rcU9"
      },
      "source": [
        "\n",
        "### **ACLARACIÓN**\n",
        "\n",
        "No pude trabajar con este RDD que arme y no estaría entendiendo el porqué.\n",
        "Quise reducir para encontrar el minimo y no puedo.\n",
        "Quiero filtrar por un numero y tampoco puedo.\n",
        "\n",
        "Ya casi es la hora de entrega, así que por lo tanto lo dejo así. Tuve poco tiempo para realizar el tp y estoy por entregar a ultimo momento si no le hubiera consultado a mi corrector sobre esto. \n",
        "\n",
        "Lo que me hubiera gustado hacer para terminar:\n",
        "\n",
        "1) Aplicar un reduce para encontrar la distancia minima.\n",
        "\n",
        "2) Filtrar por esa distancia y obtener los usuarios mas cercanos\n",
        "\n",
        "Este ejercicio me toco en el tp de Pandas, resulta que hay casos particulares con distancia 0 ya que están en la misma posición.\n",
        "\n",
        "Lo que hubiera hecho, sería comprobar lo anterior, y luego volver a hacer lo mismo pero con el segundo minimo (distinto de cero)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1Nc8Obn1Mb6"
      },
      "source": [
        "Dejo los problemas que tuve:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km0H7uBE9u9q"
      },
      "outputs": [],
      "source": [
        "type(rdd_vecinos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTtlCJPFrrCf"
      },
      "outputs": [],
      "source": [
        "rdd_vecinos.reduce(lambda a,b: a[1][1] if a[1][1] < b[1][1] else b[1][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNZOfQ6J4BCH"
      },
      "outputs": [],
      "source": [
        "rdd_vecinos.map(lambda x: x[1][1]).reduce(lambda a,b: a if a < b else b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAiAG5SqyHe4"
      },
      "outputs": [],
      "source": [
        "rdd_vecinos.filter(lambda x: x[1][1] == 0).collect()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "38_TP2_Datos.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}